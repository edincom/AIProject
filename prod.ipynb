{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27e5d56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API KEY information\n",
    "load_dotenv(override=True)\n",
    "\n",
    "from langchain_mistralai import ChatMistralAI, MistralAIEmbeddings\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5518043",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters and ChatMistral object creation\n",
    "\n",
    "\n",
    "# Create the ChatMistralAI object\n",
    "llm = ChatMistralAI(\n",
    "    temperature=1,  # Low temperature for more focused responses\n",
    "    model=\"mistral-small-latest\", \n",
    ")\n",
    "\n",
    "#If we want to understand pictures, we should use this model : \"pixtral-12b-2409\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f74b0f",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84096225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages in the document: 308\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load Documents\n",
    "loader = PyMuPDFLoader(\"Data/Atlas.pdf\")\n",
    "docs = loader.load()\n",
    "print(f\"Number of pages in the document: {len(docs)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58adbe3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of split chunks: 696\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Split Documents\n",
    "custom_separators = [\n",
    "    \"\\n \\n\",        # paragraphs\n",
    "    \"\\n\",         # lines\n",
    "    \". \",         # sentence-ish boundary\n",
    "    \"; \",         # clause boundary\n",
    "    \", \",         # phrase boundary\n",
    "    \" \",          # words\n",
    "    \"\"            # fallback: characters\n",
    "]\n",
    "text_splitter = RecursiveCharacterTextSplitter(separators = custom_separators, chunk_size=500, chunk_overlap=50)      #Paramètre à modifier par la suite pour de meilleur performance\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "print(f\"Number of split chunks: {len(split_documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b469c310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Comor\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Generate Embeddings\n",
    "embeddings = MistralAIEmbeddings(model=\"mistral-embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc73c795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Create and Save the Database\n",
    "# Create a vector store\n",
    "vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)\n",
    "print(\"Vector store created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69a7523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Create Retriever\n",
    "# Search and retrieve information contained in the documents\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b39fd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Create Prompt\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "\n",
    "#Context: \n",
    "{context}\n",
    "\n",
    "#Question:\n",
    "{question}\n",
    "\n",
    "#Answer:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb16f2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Setup LLM\n",
    "llm = ChatMistralAI(model=\"mistral-small-latest\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45f6c4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Create Chain\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bd5bb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je ne sais pas.\n",
      "-----\n",
      "D'après le contexte fourni, l'Islande est le premier pays à avoir légalisé l'avortement, dès 1934.\n"
     ]
    }
   ],
   "source": [
    "#Exemple\n",
    "\n",
    "# Run Chain\n",
    "# Input a query about the document and print the response\n",
    "question = \"Qui a gagné le ballon d'or en 2009\"\n",
    "response = chain.invoke(question)\n",
    "print(response)\n",
    "print(\"-----\")\n",
    "question = \"Quel pays a légalisé l'avortement en premier dans le monde ?\"\n",
    "response = chain.invoke(question)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614d87cd",
   "metadata": {},
   "source": [
    "# Prompt engineering\n",
    "\n",
    "Here we setup a basic template for our prompt engineering.\n",
    "In our case, the LLM will be a specialist in geography, in secondary school.\n",
    "\n",
    "The student will interact with the LLM in two different ways :\n",
    "    -He can ask any type of question about any topic in the course.\n",
    "    -He can ask to have his knowledge tested (he will then receive a score on his answer and a feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a7c978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persona prompt, specific for when the student has a question about a specific part of the course\n",
    "\n",
    "persona_template = (\n",
    "    \"Act as a supportive but rigorous geography teacher.\\n\" \\\n",
    "    \"Your tone should be constructive, specific, and pedagogical.\\n\" \\\n",
    "        \"\"\"Tu es un professeur de géographie avec 20 ans d'expérience, et ton but est de répondre aux questions d'un élève en difficulté.\n",
    "            Tu es encourageant, mais tout de fois rigoureux quant à la précision de tes réponses.\n",
    "\n",
    "    CONTRAINTES:\n",
    "    1. Utilise UNIQUEMENT le contexte fourni qui vient d .\n",
    "    2. Cite chaque fait avec la page sous forme [Page X].\n",
    "    3. Ne fabrique rien.\n",
    "\n",
    "    Format attendu:\n",
    "    Réponse concise en français.\n",
    "    CITES: Page: X,Y,... (liste unique de pages utilisées)\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Contexte:\n",
    "    {context}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "scores = \"\"\"\n",
    "- Pertinence : Est-ce que l'étudiant répond bien à la question posé et non pas à autre chose  /30;\n",
    "- Faits non correctes: Est-ce qu'il y'a des faits qui ne sont pas correctes dans la réponse  /30;\n",
    "- Faits manquants : Est-ce que tous les faits attendus sont bien présent dans la réponse  /30;\n",
    "- Stucture : Est-ce que la réponse est bien stucturée /10;\n",
    "\"\"\"\n",
    "\n",
    "test_template = (    f\"Act as a supportive but rigorous history teacher.\\n\"\n",
    "    \"Your goal is to generate a question based on the course.\"             \n",
    "    \"The student gives you an answer and your goal is to evaluate it.\\n\"\n",
    "    \"Assignment requirement: {task_description}\\n\"\n",
    "    \"Grading rubric: {grading_rubric}\\n\"\n",
    "    \"Return ONLY a JSON object with these keys:\\n\"\n",
    "    \"- Section: the general theme of the question\\n\"\n",
    "    \"- Question: the question you asked the student\\n\"\n",
    "    \"- Answer: The answer the student gave\\n\"\n",
    "    \"- grade: number (0-100), must equal sum of all scores\\n\"\n",
    "    \"- scores: f{scores} \\n\"\n",
    "    \"- advice: array of short, actionable improvement suggestions\\n\"\n",
    "    \"Constraints: grade MUST equal Pertinence+Faits non correctes + Faits manquants + Structure. No extra text outside the JSON.\\n\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8370eff",
   "metadata": {},
   "source": [
    "# Data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f807f484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'student_results.db' ready\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Create the SQLite database\n",
    "# -------------------------------\n",
    "conn = sqlite3.connect('student_results.db')  # This creates a file on disk\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create table for storing answers and grading\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS student_results (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    student_name TEXT,\n",
    "    question TEXT,\n",
    "    answer TEXT,\n",
    "    grade REAL,\n",
    "    scores TEXT,        -- we'll store JSON as a string\n",
    "    advice TEXT\n",
    ")\n",
    "''')\n",
    "conn.commit()\n",
    "print(\"Database 'student_results.db' ready\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Function to save a result\n",
    "# -------------------------------\n",
    "def save_result(student_name, question, answer, grading_json):\n",
    "    \"\"\"\n",
    "    grading_json: dictionary returned by LLM in test mode\n",
    "    \"\"\"\n",
    "    # Convert the 'scores' dict to a JSON string\n",
    "    scores_str = json.dumps(grading_json.get(\"scores\", {}), ensure_ascii=False)\n",
    "\n",
    "    cursor.execute('''\n",
    "        INSERT INTO student_results (student_name, question, answer, grade, scores, advice)\n",
    "        VALUES (?, ?, ?, ?, ?, ?)\n",
    "    ''', (\n",
    "        student_name,\n",
    "        question,\n",
    "        answer,\n",
    "        grading_json.get(\"grade\", 0),\n",
    "        scores_str,\n",
    "        grading_json.get(\"advice\", \"\")\n",
    "    ))\n",
    "    conn.commit()\n",
    "    print(f\"Result for {student_name} saved successfully!\")\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Example usage\n",
    "# -------------------------------\n",
    "\n",
    "# Suppose we have a grading result from the LLM (already parsed as JSON)\n",
    "example_grading_json = {\n",
    "    \"Section\": \"Histoire\",\n",
    "    \"Question\": \"Quels furent les principaux événements qui ont marqué le début de la Seconde Guerre mondiale en Europe ?\",\n",
    "    \"Answer\": \"L'invasion de la Pologne par l'Allemagne, et le fait qu'il y'avait une crise économique assez forte\",\n",
    "    \"grade\": 40,\n",
    "    \"scores\": {\n",
    "        \"Pertinence\": 20,\n",
    "        \"Faits non correctes\": 20,\n",
    "        \"Faits manquants\": 40,\n",
    "        \"Structure\": 10\n",
    "    },\n",
    "    \"advice\": \"La réponse mentionne correctement l'invasion de la Pologne, qui est un événement clé. Cependant, la crise économique, bien que pertinente, n'est pas un événement marquant du début de la guerre...\"\n",
    "}\n",
    "\n",
    "#save_result(\"Edin\", example_grading_json[\"Question\"], example_grading_json[\"Answer\"], example_grading_json)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760ad84e",
   "metadata": {},
   "source": [
    "# Vector embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56125cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Comor\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore saved to 'faiss_index/'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# FULL WORKING VERSION — RAG + PERSONA CHAIN + GRADING CHAIN\n",
    "# ============================================================\n",
    "\n",
    "from langchain_mistralai import ChatMistralAI, MistralAIEmbeddings\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnableBranch\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. LLM CONFIG\n",
    "# ============================================================\n",
    "\n",
    "llm = ChatMistralAI(\n",
    "    model=\"mistral-small-latest\",   # Vision model would be: pixtral-12b-2409\n",
    "    temperature=1\n",
    ")\n",
    "\n",
    "# OPTIONAL: if you want vision, replace above with:\n",
    "# llm = ChatMistralAI(model=\"pixtral-12b-2409\", temperature=1)\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. LOAD DOCUMENTS (PDF)\n",
    "# ============================================================\n",
    "\n",
    "loader = PyMuPDFLoader(\"Data/Atlas.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. SPLIT DOCUMENTS\n",
    "# ============================================================\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\n",
    "        \"\\nCHAPITRE\", \"\\n##\", \"\\n###\", \"\\nSection\", \"\\n\\n\", \"\\n\", \".\", \" \", \"\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. EMBEDDINGS + VECTORSTORE + RETRIEVER\n",
    "# ============================================================\n",
    "\n",
    "embeddings = MistralAIEmbeddings(model=\"mistral-embed\")\n",
    "\n",
    "vectorstore = FAISS.from_documents(split_documents, embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Save to disk\n",
    "vectorstore.save_local(\"faiss_index\")\n",
    "print(\"Vectorstore saved to 'faiss_index/'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d37642",
   "metadata": {},
   "source": [
    "# Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e546a08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore loaded successfully\n",
      "=== Tutor System Running ===\n",
      "Ask a question to the teacher, or type 'test' to grade an answer.\n",
      "\n",
      "\n",
      "--- Question générée automatiquement ---\n",
      "Question pertinente pour un élève :\n",
      "\n",
      "\"En vous basant sur le contexte fourni, expliquez comment l'Angleterre a utilisé son influence diplomatique pour façonner la carte politique de l'Europe après le Congrès de Vienne en 1815. Quels étaient ses objectifs et quels moyens a-t-elle employés pour les atteindre ?\"\n",
      "\n",
      "Cette question encourage l'élève à analyser les actions de l'Angleterre dans le contexte post-napoléonien, à comprendre ses motivations stratégiques et à évaluer l'impact de ses politiques sur les autres nations européennes.\n",
      "\n",
      "--- JSON Grading Result ---\n",
      "{'Section': 'Histoire', 'Question': \"En vous basant sur le contexte fourni, expliquez comment l'Angleterre a utilisé son influence diplomatique pour façonner la carte politique de l'Europe après le Congrès de Vienne en 1815. Quels étaient ses objectifs et quels moyens a-t-elle employés pour les atteindre ?\", 'Answer': 'Grace a la piraterie', 'grade': 0, 'scores': {'Pertinence': 0, 'Faits non correctes': 30, 'Faits manquants': 30, 'Structure': 0}, 'advice': \"La réponse ne répond pas du tout à la question posée. Il est important de fournir une réponse structurée et pertinente qui aborde les objectifs et les moyens utilisés par l'Angleterre pour influencer la carte politique de l'Europe après le Congrès de Vienne. Il est également crucial de fournir des faits corrects et complets pour obtenir une bonne note.\"}\n",
      "\n",
      "Note : 0\n",
      "Conseils : La réponse ne répond pas du tout à la question posée. Il est important de fournir une réponse structurée et pertinente qui aborde les objectifs et les moyens utilisés par l'Angleterre pour influencer la carte politique de l'Europe après le Congrès de Vienne. Il est également crucial de fournir des faits corrects et complets pour obtenir une bonne note.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_mistralai import MistralAIEmbeddings\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = MistralAIEmbeddings(model=\"mistral-embed\")\n",
    "\n",
    "# Load the vectorstore (allow unsafe deserialization since you created it)\n",
    "vectorstore = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "print(\"Vectorstore loaded successfully\")\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. PERSONA CHAIN (Teacher mode + RAG)\n",
    "# ============================================================\n",
    "\n",
    "persona_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"Tu es un professeur bienveillant. Explique simplement mais sans infantiliser. \"\n",
    "     \"Appuie-toi uniquement sur le contexte fourni.\"),\n",
    "    (\"human\",\n",
    "     \"Question: {question}\\n\\n\"\n",
    "     \"Contexte issu des documents:\\n{context}\")\n",
    "])\n",
    "\n",
    "persona_chain = (\n",
    "    persona_template\n",
    "    | llm\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6. GRADING CHAIN (Automatic evaluation)\n",
    "# ============================================================\n",
    "\n",
    "test_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"Tu es un correcteur automatique. Évalue la réponse de l'élève selon les critères fournis.\"),\n",
    "    (\"human\",\n",
    "     #\"Instruction donnée à l'élève : {task_description}\\n\"\n",
    "     \"Barème : {grading_rubric}\\n\"\n",
    "     \"Question : {question}\\n\"\n",
    "     \"Réponse de l'élève : {answer}\\n\\n\"\n",
    "     \"Donne une note sur 20 + justification.\")\n",
    "])\n",
    "\n",
    "test_chain = (\n",
    "    test_template\n",
    "    | llm\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7. RAG WRAPPER — run retrieval only if needed\n",
    "# ============================================================\n",
    "\n",
    "def rag_logic(inputs):\n",
    "    query = inputs.get(\"question\", \"\")\n",
    "    if not query:\n",
    "        inputs[\"context\"] = \"\"\n",
    "        return inputs\n",
    "\n",
    "    docs = retriever.invoke(query)\n",
    "    ctx = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    inputs[\"context\"] = ctx\n",
    "    return inputs\n",
    "\n",
    "\n",
    "rag_chain = RunnableLambda(rag_logic)\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8. ROUTING — decide whether to use Persona or Test chain\n",
    "# ============================================================\n",
    "\n",
    "def route(inputs):\n",
    "    \"\"\"\n",
    "    If 'answer' is provided → grading mode.\n",
    "    Otherwise → persona/teacher mode.\n",
    "    \"\"\"\n",
    "    return \"answer\" not in inputs\n",
    "\n",
    "\n",
    "conditional_chain = RunnableBranch(\n",
    "    # condition → persona mode\n",
    "    (\n",
    "        lambda inputs: route(inputs),\n",
    "        rag_chain | persona_chain\n",
    "    ),\n",
    "    # fallback → grading mode\n",
    "    test_template | llm\n",
    ")\n",
    "\n",
    "def generate_test_question(criteria):\n",
    "    \"\"\"\n",
    "    Generate a test question using document context (RAG) and student instructions.\n",
    "    \"\"\"\n",
    "    # Step 1: Retrieve relevant context using RAG\n",
    "    # Use invoke() method to retrieve documents\n",
    "    docs = retriever.invoke(criteria)\n",
    "\n",
    "    context_text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    # Step 2: Prompt for question generation using the retrieved context\n",
    "    question_gen_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "         \"Tu es un professeur bienveillant et rigoureux. \"\n",
    "         \"À partir du contexte fourni, génère une question pertinente pour un élève.\"),\n",
    "        (\"human\",\n",
    "         \"Instructions : {criteria}\\n\\nContexte : {context}\")\n",
    "    ])\n",
    "\n",
    "    question_gen_chain = question_gen_prompt | llm\n",
    "\n",
    "    generated_question = question_gen_chain.invoke({\n",
    "        \"criteria\": criteria,\n",
    "        \"context\": context_text\n",
    "    }).content.strip()\n",
    "\n",
    "    return generated_question\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 9. MAIN ENTRYPOINT\n",
    "# ============================================================\n",
    "\n",
    "def respond(inputs):\n",
    "    return conditional_chain.invoke(inputs)\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 10. INTERACTIVE TESTING WITH input()\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"=== Tutor System Running ===\")\n",
    "    print(\"Ask a question to the teacher, or type 'test' to grade an answer.\\n\")\n",
    "\n",
    "    mode = input(\"Mode (teach/test): \").strip().lower()\n",
    "\n",
    "    if mode == \"teach\":\n",
    "        question = input(\"Your question: \")\n",
    "        result = respond({\"question\": question})\n",
    "        print(\"\\n--- Teacher answer ---\")\n",
    "        print(result)\n",
    "\n",
    "    elif mode == \"test\":\n",
    "        # Étudiant fournit uniquement le barème et sa réponse\n",
    "        rubric = input(\"Barème : \")\n",
    "\n",
    "        # --- Etape 1 : Generate question using RAG context ---\n",
    "        generated_question = generate_test_question(rubric)\n",
    "        print(\"\\n--- Question générée automatiquement ---\")\n",
    "        print(generated_question)\n",
    "\n",
    "        # --- Étape 2 : l'élève fournit sa réponse ---\n",
    "        answer = input(\"\\nRéponse de l'élève : \")\n",
    "\n",
    "        # --- Étape 3 : prompt de correction (JSON output) ---\n",
    "        scores_text = (\n",
    "            \"- Pertinence : ... /30;\\n\"\n",
    "            \"- Faits non correctes : ... /30;\\n\"\n",
    "            \"- Faits manquants : ... /30;\\n\"\n",
    "            \"- Structure : ... /10;\"\n",
    "        )\n",
    "\n",
    "        test_prompt_template = ChatPromptTemplate.from_messages([\n",
    "            (\"system\",\n",
    "            \"Act as a supportive but rigorous history teacher.\\n\"\n",
    "            \"Your goal is to evaluate the student's answer and return ONLY a JSON object.\"),\n",
    "            (\"human\",\n",
    "            \"Grading rubric: {grading_rubric}\\n\"\n",
    "            \"Question: {question}\\n\"\n",
    "            \"Answer: {answer}\\n\"\n",
    "            \"Scores template: {scores_text}\\n\"\n",
    "            \"Constraints: grade MUST equal sum of all scores.\\n\"\n",
    "            \"Return a JSON object with keys:\\n\"\n",
    "            \"- Section\\n\"\n",
    "            \"- Question\\n\"\n",
    "            \"- Answer\\n\"\n",
    "            \"- grade (0-100)\\n\"\n",
    "            \"- scores\\n\"\n",
    "            \"- advice\\n\"\n",
    "            \"No extra text or Markdown, ONLY JSON.\")\n",
    "        ])\n",
    "\n",
    "        test_chain = test_prompt_template | llm\n",
    "\n",
    "        grading_result = test_chain.invoke({\n",
    "            \"grading_rubric\": rubric,\n",
    "            \"question\": generated_question,\n",
    "            \"answer\": answer,\n",
    "            \"scores_text\": scores_text\n",
    "        })\n",
    "\n",
    "        # --- Étape 4 : transformer la string en dictionnaire Python ---\n",
    "        import json\n",
    "\n",
    "        raw_output = grading_result.content.strip()\n",
    "\n",
    "        # Retirer les ```json ou ``` éventuels\n",
    "        if raw_output.startswith(\"```\"):\n",
    "            raw_output = \"\\n\".join(raw_output.split(\"\\n\")[1:-1])\n",
    "\n",
    "        try:\n",
    "            grading_json = json.loads(raw_output)\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Erreur : le LLM n'a pas retourné un JSON valide\")\n",
    "            grading_json = None\n",
    "\n",
    "        # --- Étape 5 : afficher le résultat ---\n",
    "        if grading_json:\n",
    "            print(\"\\n--- JSON Grading Result ---\")\n",
    "            print(grading_json)\n",
    "            print(\"\\nNote :\", grading_json[\"grade\"])\n",
    "            print(\"Conseils :\", grading_json[\"advice\"])\n",
    "        #save_result(\"Edin\", grading_json[\"Question\"], grading_json[\"Answer\"], grading_json)\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"Unknown mode.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dc7195a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Edin', 'Quelles étaient les principales causes de la Première Guerre mondiale et comment ont-elles conduit à son déclenchement en 1914 ?', \"L'assassination de l'archeduc François ferdinant\", 20.0, '{\"Pertinence\": 10, \"Faits non correctes\": 20, \"Faits manquants\": 20, \"Structure\": 0}', \"Votre réponse est incomplète et manque de structure. Vous avez mentionné un événement important, mais vous devez inclure d'autres causes majeures comme le nationalisme, l'impérialisme, le militarisme et les alliances. De plus, vous devez expliquer comment ces facteurs ont conduit à la guerre en 1914. Travaillez sur la clarté et l'organisation de votre réponse.\")\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 4. Query the database\n",
    "# -------------------------------\n",
    "cursor.execute(\"SELECT * FROM student_results\")\n",
    "rows = cursor.fetchall()\n",
    "for row in rows:\n",
    "    print(row)\n",
    "\n",
    "# Close connection when done\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9353a404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pertinence': 0, 'Faits non correctes': 30, 'Faits manquants': 30, 'Structure': 10}\n"
     ]
    }
   ],
   "source": [
    "print(grading_json['scores'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
